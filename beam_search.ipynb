{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "beam_search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6qwjQGRekL4",
        "outputId": "1d4f7136-3b3d-4a51-f7f9-dbbf49703cd7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_20ohjigege"
      },
      "source": [
        "import re\n",
        "import json\n",
        "import os\n",
        "import itertools\n",
        "from math import log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L662vkyPgs67"
      },
      "source": [
        "# Xóa dấu tiếng Việt\n",
        "def remove_vn_accent(s):\n",
        "    s = re.sub('[áàảãạăắằẳẵặâấầẩẫậ]', 'a', s)\n",
        "    s = re.sub('[éèẻẽẹêếềểễệ]', 'e', s)\n",
        "    s = re.sub('[óòỏõọôốồổỗộơớờởỡợ]', 'o', s)\n",
        "    s = re.sub('[íìỉĩị]', 'i', s)\n",
        "    s = re.sub('[úùủũụưứừửữự]', 'u', s)\n",
        "    s = re.sub('[ýỳỷỹỵ]', 'y', s)\n",
        "    s = re.sub('đ', 'd', s)\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1hBPibDgyJt"
      },
      "source": [
        "# Download VN syllables\n",
        "!wget -O vn_syllables.txt \"https://gist.githubusercontent.com/nguyenvanhieuvn/8d7c3440590a6db732ef6e05498c1566/raw/0164ccb7094b22a48a52844e7fa748cf2820cec9/all-vietnamese-syllables.txt(G%25C3%25B5%2520d%25E1%25BA%25A5u%2520ki%25E1%25BB%2583u%2520c%25C5%25A9)\"\n",
        "# Download language model\n",
        "!wget \"https://github.com/nguyenvanhieuvn/vn-accent-resoration/raw/master/vn_en_nextwords.txt.zip\"\n",
        "!unzip vn_en_nextwords.txt.zip\n",
        "# Download test data\n",
        "!wget \"https://github.com/nguyenvanhieuvn/vn-accent-resoration/raw/master/test.txt\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4K4Q4f2NWUs"
      },
      "source": [
        "lm = {}\n",
        "next_for_repair = {}\n",
        "output = []\n",
        "for line in open('/content/vn_en_nextwords.txt'):\n",
        "    out = {}\n",
        "    data = json.loads(line)\n",
        "    key = data['s']\n",
        "#       print(key)\n",
        "    if key == \"nơi\":\n",
        "        next_for_repair = data['next']\n",
        "        data['next'].update({\"ĐKHK\": 200000})\n",
        "        data['next'].update({\"đkhk\": 200000})\n",
        "        data['next'].update({\"thường\": 200000})\n",
        "        data['next'].update({\"cư\": 200000})\n",
        "    if key == 'thường':\n",
        "        data['next'].update({\"trú\": 200000})\n",
        "        # print(data['next'])\n",
        "    if key == 'nguyên':\n",
        "        data['next'].update({\"quán\": 200000})\n",
        "        # print(data['next'])\n",
        "    out.update(s = key, sum = data['sum'],next= data['next'])\n",
        "    output.append(out)\n",
        "out = {}\n",
        "out.update(s = 'đkhk', sum = 2000000, next = {\"thường\": 200000, \"thưởng\":100})\n",
        "output.append(out)\n",
        "with open(\"nextwords.txt\", 'w') as writeout:\n",
        "    for dict in output:\n",
        "        dict = json.dumps(dict)\n",
        "        # print(dict)\n",
        "        writeout.writelines(str(dict) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJxEZ3P9hQGK"
      },
      "source": [
        "# Tạo bộ từ điển sinh dấu câu cho các từ không dấu\n",
        "map_accents = {}\n",
        "for word in open('vn_syllables.txt').read().splitlines():\n",
        "  # print(word)\n",
        "  word = word.lower()\n",
        "  # print(word)\n",
        "  no_accent_word = remove_vn_accent(word)\n",
        "  # print(no_accent_word)\n",
        "  if no_accent_word not in map_accents:\n",
        "    map_accents[no_accent_word] = set()\n",
        "    # print(map_accents)\n",
        "  map_accents[no_accent_word].add(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbrvxOJLiKO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87fcc83d-70fe-429a-dd08-1493c1adb9d2"
      },
      "source": [
        "print(map_accents['dkhk'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'đkhk'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFDH2rCRqCKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf327e5-48f1-421a-c822-cfe18b45214c"
      },
      "source": [
        "# Đọc lm\n",
        "lm = {}\n",
        "for line in open('nextwords.txt'):\n",
        "  data = json.loads(line)\n",
        "  key = data['s']\n",
        "  lm[key] = data\n",
        "vocab_size = len(lm)\n",
        "total_word = 0\n",
        "for word in lm:\n",
        "  total_word += lm[word]['sum']\n",
        "print(vocab_size, total_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50001 6345849795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S55LZeC_5HMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239baca3-c176-4701-86f2-b5baf4c23217"
      },
      "source": [
        "lm['đkhk']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'next': {'thường': 200000, 'thưởng': 100}, 's': 'đkhk', 'sum': 2000000}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFUYIbcU9LZI"
      },
      "source": [
        "# tính xác suất dùng smoothing\n",
        "def get_proba(current_word, next_word):\n",
        "  if current_word not in lm:\n",
        "    return 1 / total_word;\n",
        "  if next_word not in lm[current_word]['next']:\n",
        "    return 1 / (lm[current_word]['sum'] + vocab_size)\n",
        "  return (lm[current_word]['next'][next_word] + 1) / (lm[current_word]['sum'] + vocab_size)\n",
        "\n",
        "# def get_proba(current_word, next_word):\n",
        "#   try:\n",
        "#     return (lm[current_word]['next'][next_word]) / (lm[current_word]['sum'])\n",
        "#   except:\n",
        "#     return 1e-30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBQlSHgR34-h"
      },
      "source": [
        "# hàm beam search\n",
        "def beam_search(words, k=3):\n",
        "  sequences = []\n",
        "  for idx, word in enumerate(words):\n",
        "    if idx == 0:\n",
        "      sequences = [([x], 0.0) for x in map_accents.get(word, [word])]\n",
        "    else:\n",
        "      all_sequences = []\n",
        "      for seq in sequences:\n",
        "        for next_word in map_accents.get(word, [word]):\n",
        "          current_word = seq[0][-1]\n",
        "          proba = get_proba(current_word, next_word)\n",
        "          # print(current_word, next_word, proba, log(proba))\n",
        "          proba = log(proba)\n",
        "          new_seq = seq[0].copy()\n",
        "          new_seq.append(next_word)\n",
        "          all_sequences.append((new_seq, seq[1] + proba))\n",
        "      # print(all_sequences) \n",
        "      all_sequences = sorted(all_sequences,key=lambda x: x[1], reverse=True)\n",
        "      sequences = all_sequences[:k]\n",
        "  return sequences\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko_N1RvRsfbV"
      },
      "source": [
        "# tiền xử lý text\n",
        "def preprocess(sentence):\n",
        "  sentence = sentence.lower()\n",
        "  sentence = re.sub(r'[.,~`!@#$%\\^&*\\(\\)\\[\\]\\\\|:;\\'\"]+', ' ', sentence)\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARdWnejy38xn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a12d12-8bdb-4230-cf63-9033bd1ea91d"
      },
      "source": [
        "# test 1 câu\n",
        "# import time\n",
        "# t1 = time.time()\n",
        "sentence = \"Nởi DKHK thương trù\"\n",
        "sentence = preprocess(sentence)\n",
        "_sentence = remove_vn_accent(sentence)\n",
        "words = _sentence.split()\n",
        "results = beam_search(words, k=5)\n",
        "print('INP:', sentence)\n",
        "# print(time.time()-t1)\n",
        "print('OUT:', ' '.join(results[0][0]))\n",
        "print('CMP:', ' '.join(results[0][0]) == sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INP: nởi dkhk thương trù\n",
            "OUT: nơi đkhk thường trú\n",
            "CMP: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ87WWXQzQOe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bf6b9b54-6ad1-46b0-8757-91686dfbbf09"
      },
      "source": [
        "# test qua bộ test ~ 5000 câu\n",
        "k = 10\n",
        "sentences = open('test.txt').read().splitlines()\n",
        "test_size = len(sentences)\n",
        "print(test_size)\n",
        "correct = 0\n",
        "for sent in sentences:\n",
        "  try:\n",
        "    sent = preprocess(sent)\n",
        "    _sent = remove_vn_accent(sent)\n",
        "    words = _sent.split()\n",
        "    results = beam_search(words, k)\n",
        "    if ' '.join(results[0][0]) == sent:\n",
        "      correct += 1\n",
        "  except:\n",
        "    print('err', sent)\n",
        "    break\n",
        "\n",
        "print(correct / test_size)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4983\n",
            "0.32691149909692957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCpzbFlw2PrL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}